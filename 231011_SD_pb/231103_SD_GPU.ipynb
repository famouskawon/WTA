{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단한 상황\n",
    "- Weapon : 50\n",
    "- Target : 100 (weight : 1~100)\n",
    "- 적재량 : 3\n",
    "\n",
    "- 상황 구현\n",
    "- 에이전트 구현\n",
    "\n",
    "kernel은 base\n",
    "\n",
    "목적함수 대신, 새로운 결과치를 내야 한다.\n",
    "1개 요격 시 보상인데, 오래 걸렸을 수록 감쇠된 보상을 얻어야 한다.\n",
    "그런데 위험도에 따라 보상이 달라져야겠지.\n",
    "그럼 weight 만큼의 보상을 주면 되지 않을까"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.random.seed(42)는 요격확률과 초기 위험도를 설정하게 해 줄것이다.\n",
    "\n",
    "\n",
    "random.seed(42)는 요격시 실제로 요격되는지에 설정할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리 import\n",
    "import collections\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "buffer_limit = 160\n",
    "gamma = 0.5\n",
    "learning_rate = 0.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "class WTAWorld():\n",
    "    def __init__(self, W, T, M):\n",
    "        self.W = W\n",
    "        self.T = T\n",
    "        self.M = M\n",
    "\n",
    "        # Target t에 weapon w를 할당할 때의 요격확률 생성\n",
    "        self.PK_wt = torch.rand(W, T, device=device)\n",
    "        \n",
    "        # Target index 할당\n",
    "        self.targets = torch.arange(T, device=device)\n",
    "        \n",
    "        # Target 별 초기 위험도 할당\n",
    "        self.init_weights = torch.randint(1, 100, (T,), device=device)\n",
    "        \n",
    "        # Target의 현재 위험도 설정 (0 = 파괴)\n",
    "        self.weights = self.init_weights.clone()\n",
    "        self.M_W = [self.M] * self.W\n",
    "        self.left_M_W = self.M_W\n",
    "\n",
    "    def step(self, theta_wt):\n",
    "        indices = torch.nonzero(theta_wt == 1).tolist()\n",
    "\n",
    "        for coord in indices:\n",
    "            w, t = coord\n",
    "            if self.PK_wt[w][t] > 0 and self.left_M_W[w] > 0:\n",
    "                pk_probability = self.PK_wt[w][t].item()\n",
    "                random_value = random.random()\n",
    "                if random_value < pk_probability:\n",
    "                    self.weights[t] = 0\n",
    "                self.left_M_W[w] -= 1\n",
    "\n",
    "        done = self.is_done()\n",
    "        r = torch.sum(self.init_weights - self.weights).item()\n",
    "        self.init_weights = self.weights.clone()\n",
    "        \n",
    "        return self.PK_wt * self.weights, r, done\n",
    "\n",
    "    def is_done(self):\n",
    "        return torch.sum(torch.tensor(self.left_M_W)) == 0 or torch.sum(self.weights) == 0\n",
    "\n",
    "    def get_state(self):\n",
    "        return (self.PK_wt, self.weights, self.left_M_W)\n",
    "\n",
    "    def reset(self):\n",
    "        self.PK_wt = torch.rand(self.W, self.T, device=device)\n",
    "        self.targets = torch.arange(self.T, device=device)\n",
    "        self.init_weights = torch.randint(1, 100, (self.T,), device=device)\n",
    "        self.weights = self.init_weights.clone()\n",
    "        self.M_W = [self.M] * self.W\n",
    "        self.left_M_W = self.M_W\n",
    "        \n",
    "        return self.PK_wt * self.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greedy Algorithm\n",
    "\n",
    "def greedy(state):\n",
    "    PK_wt = state[0]\n",
    "    targets_weights = state[1]\n",
    "    left_M_W = state[2]\n",
    "    \n",
    "    w = PK_wt.shape[0]\n",
    "    t = PK_wt.shape[1]\n",
    "    \n",
    "    # w의 발사 여부\n",
    "    m_w = [1 if m > 0 else m for m in left_M_W]\n",
    "    # 할당 여부를 나타내는 theta_wt\n",
    "    theta_wt = np.zeros((w, t), dtype=int)\n",
    "\n",
    "    flattened = (PK_wt*targets_weights).flatten()\n",
    "    sorted_indices = np.argsort(flattened)[::-1]\n",
    "    \n",
    "    i = 0\n",
    "    indices_list = []\n",
    "    while True :\n",
    "        if i == w * t :\n",
    "            break\n",
    "        v = sorted_indices[i]\n",
    "        row = v // t # Weapon\n",
    "        col = v % t # Target\n",
    "\n",
    "        if left_M_W[row] > 0 and m_w[row] == 1:\n",
    "            \n",
    "            m_w[row] -= 1\n",
    "            theta_wt[row][col] = 1\n",
    "            indices_list.append(v)\n",
    "            print(f\"weapon {row}를 target {col}에 할당, 요격확률*가중치:{flattened[v]:.2f} \")\n",
    "\n",
    "        # 할당할 수 있는 유도탄의 개수를 모두 소모했다면 종료.\n",
    "        if sum(left_M_W) == 0:\n",
    "            break\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    return theta_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU라 안 됨\n",
    "# env=WTAWorld(50,100,2)\n",
    "# step_i = 1\n",
    "# while True : \n",
    "#     print(f\"{step_i}번째 스텝\")\n",
    "#     theta_wt =greedy(env.get_state())\n",
    "#     print(\"------발사------\")\n",
    "#     s_prime, r, done = env.step(theta_wt)\n",
    "#     print(\"------요격결과------\")\n",
    "#     print(env.get_state()[1])\n",
    "#     print(f\"보상: {r}\")\n",
    "#     if env.is_done():\n",
    "#         break\n",
    "#     step_i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    env = WTAWorld(50,100,2)\n",
    "    step_i = 1\n",
    "    while True : \n",
    "        print(f\"{step_i}번째 스텝\")\n",
    "        theta_wt = greedy(env.get_state())\n",
    "        print(\"------발사------\")\n",
    "        s_prime, r, done = env.step(theta_wt)\n",
    "        print(\"------요격결과------\")\n",
    "        print(wta.get_state()[0][1])\n",
    "        if env.is_done():\n",
    "            break\n",
    "        step_i+=1\n",
    "        print(f\"보상: {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "    \n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "        \n",
    "    def sample(self, n):\n",
    "        mini_batch = random.sample(self.buffer, n)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        \n",
    "        for transition in mini_batch:\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append(a)\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "        \n",
    "        # print(torch.tensor(s_lst, dtype=torch.float))\n",
    "        # print(torch.tensor(a_lst))\n",
    "        # print(torch.tensor(r_lst))\n",
    "        # print(torch.tensor(s_prime_lst, dtype=torch.float))\n",
    "        # print(torch.tensor(done_mask_lst))\n",
    "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), torch.tensor(done_mask_lst)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnet(nn.Module):\n",
    "    def __init__(self, W, T):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.W = W\n",
    "        self.T = T\n",
    "        self.fc1 = nn.Linear(self.W*self.T, self.W*self.T*2)\n",
    "        self.fc2 = nn.Linear(self.W*self.T*2, self.W*self.T*2)\n",
    "        self.fc3 = nn.Linear(self.W*self.T*2, self.W*self.T)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    def sample_action(self, obs, epsilon):\n",
    "        out = self.forward(obs)\n",
    "        # print(out)\n",
    "        # print(out.shape)\n",
    "        reshaped_out = out.reshape(self.W,self.T)\n",
    "        \n",
    "        one_hot = torch.zeros_like(reshaped_out)\n",
    "        \n",
    "        coin = random.random()\n",
    "        if coin < epsilon:\n",
    "            random_indices = torch.randint(0, reshaped_out.shape[1], (reshaped_out.shape[0],))\n",
    "            one_hot[torch.arange(reshaped_out.shape[0]), random_indices] = 1\n",
    "            return one_hot\n",
    "        else :\n",
    "            max_indices = torch.argmax(reshaped_out, dim=1)\n",
    "            one_hot[torch.arange(reshaped_out.shape[0]), max_indices] = 1\n",
    "            return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(q, q_target, memory, optimizer):\n",
    "    # Transfer models to GPU\n",
    "    q = q.to(device)\n",
    "    q_target = q_target.to(device)\n",
    "    \n",
    "    for i in range(10):\n",
    "        s, a, r, s_prime, done_mask = memory.sample(batch_size)\n",
    "        \n",
    "        # Transfer data to GPU\n",
    "        s = s.to(device)\n",
    "        a = a.to(device)\n",
    "        r = r.to(device)\n",
    "        s_prime = s_prime.to(device)\n",
    "        done_mask = done_mask.to(device)\n",
    "\n",
    "        q_out = q(s.flatten(start_dim=1))\n",
    "        q_a = a.flatten(start_dim=1) * q_out\n",
    "        max_q_prime = q_target(s_prime.flatten(start_dim=1)).max(1)[0].unsqueeze(1)\n",
    "        target = r + gamma * max_q_prime * done_mask\n",
    "        loss = F.smooth_l1_loss(q_a, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def main():\n",
    "    env = WTAWorld(10,10,3)\n",
    "\n",
    "    # Transfer the Q networks to GPU\n",
    "    q = Qnet(env.W, env.T).to(device)\n",
    "    q_target = Qnet(env.W, env.T).to(device)\n",
    "    q_target.load_state_dict(q.state_dict())\n",
    "    memory = ReplayBuffer()\n",
    "    \n",
    "    print_interval = 20\n",
    "    score = 0.0\n",
    "    optimizer = optim.Adam(q.parameters(), lr = learning_rate)\n",
    "    \n",
    "    for n_epi in range(1000):\n",
    "        epsilon = max(0.01, 0.08, - 0.01*(n_epi/200))\n",
    "        s = env.reset()\n",
    "\n",
    "        # Convert s to a tensor and transfer to GPU\n",
    "        s = s.to(device)\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            a = q.sample_action(s.flatten(), epsilon)\n",
    "            s_prime, r, done = env.step(a)  # Assuming a is a tensor with one item\n",
    "\n",
    "            # Convert s_prime to a tensor and transfer to GPU\n",
    "            s_prime = s_prime.to(device)\n",
    "            done_mask = 0.0 if done else 1.0\n",
    "            memory.put((s.cpu().numpy(), a.cpu().numpy(), r/100.0, s_prime.cpu().numpy(), done_mask))  # Assuming you want to store numpy arrays in memory\n",
    "            s = s_prime\n",
    "            score += r\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        if memory.size()>2000:\n",
    "            train(q, q_target, memory, optimizer)\n",
    "        \n",
    "        if n_epi%print_interval == 0 and n_epi !=0:\n",
    "            q_target.load_state_dict(q.state_dict())\n",
    "            print(f\"n_episode: {n_epi}, score: {(score/print_interval):.1f}, n_buffer: {memory.size()}, eps: {(epsilon*100):.1f}%\")\n",
    "            score = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_episode: 20, score: 341.6, n_buffer: 63, eps: 8.0%\n",
      "n_episode: 40, score: 324.2, n_buffer: 123, eps: 8.0%\n",
      "n_episode: 60, score: 272.1, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 80, score: 321.4, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 100, score: 313.4, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 120, score: 338.2, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 140, score: 323.9, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 160, score: 335.1, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 180, score: 342.3, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 200, score: 342.6, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 220, score: 315.2, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 240, score: 288.9, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 260, score: 355.1, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 280, score: 367.4, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 300, score: 328.4, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 320, score: 347.0, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 340, score: 346.2, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 360, score: 367.6, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 380, score: 296.9, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 400, score: 323.4, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 420, score: 310.9, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 440, score: 286.0, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 460, score: 366.1, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 480, score: 369.4, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 500, score: 317.9, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 520, score: 311.8, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 540, score: 284.0, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 560, score: 335.4, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 580, score: 302.8, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 600, score: 327.9, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 620, score: 327.9, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 640, score: 306.6, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 660, score: 329.9, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 680, score: 314.4, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 700, score: 339.4, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 720, score: 295.8, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 740, score: 304.5, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 760, score: 317.6, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 780, score: 311.9, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 800, score: 342.4, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 820, score: 321.1, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 840, score: 352.1, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 860, score: 296.3, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 880, score: 310.6, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 900, score: 329.9, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 920, score: 313.1, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 940, score: 349.6, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 960, score: 335.8, n_buffer: 160, eps: 8.0%\n",
      "n_episode: 980, score: 307.5, n_buffer: 160, eps: 8.0%\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4584, 0.0016, 0.5562,  ..., 0.3055, 0.6100, 0.7293],\n",
       "         [0.5924, 0.3393, 0.3580,  ..., 0.5522, 0.4694, 0.5062],\n",
       "         [0.2949, 0.4367, 0.6616,  ..., 0.5104, 0.2648, 0.3293],\n",
       "         ...,\n",
       "         [0.9325, 0.2087, 0.9674,  ..., 0.2131, 0.5445, 0.2883],\n",
       "         [0.3481, 0.7200, 0.4424,  ..., 0.9947, 0.3472, 0.7071],\n",
       "         [0.6363, 0.9461, 0.4184,  ..., 0.4096, 0.7083, 0.3928]],\n",
       "        device='cuda:0'),\n",
       " tensor([ 5, 83, 71, 33, 56, 32, 98, 95,  3, 60, 13, 69, 87,  9, 33, 27, 60, 42,\n",
       "         60, 74, 46, 84,  8, 20, 48, 63, 83, 13, 16, 74, 69,  5, 15, 47, 70, 39,\n",
       "         15,  3, 67,  4, 76, 57, 57, 64, 54,  6, 75, 17, 10, 17, 55, 27, 18, 67,\n",
       "         23, 24,  2, 92, 96, 37, 39, 42, 23, 20, 67, 34, 88, 43, 33, 62,  5, 11,\n",
       "         66, 52, 73, 61, 10, 53, 31, 51, 76, 55, 48, 45,  2,  4, 94, 15, 25, 53,\n",
       "         83, 38, 51, 62, 40, 22, 36, 19, 52, 23], device='cuda:0'),\n",
       " [2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "230924_milp_wta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
